{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File I/O in Python\n",
    "\n",
    "This notebook will cover the following topics:\n",
    "\n",
    "1. Opening and closing files\n",
    "2. Reading and writing text files\n",
    "3. Reading and writing binary files\n",
    "4. Using the `with` statement\n",
    "5. Using the `pickle` module\n",
    "6. Serializing objects with `pickle`\n",
    "7. Reading and writing JSON files\n",
    "\n",
    "## Opening and closing files\n",
    "\n",
    "Let's start with the basics. To open a file, we use the built-in `open()` function. The `open()` function takes two arguments: the name of the file to open and the mode in which to open it. The mode can be one of the following:\n",
    "\n",
    "* `'r'` - open for reading (default)\n",
    "* `'w'` - open for writing, truncating the file first\n",
    "* `'x'` - open for exclusive creation, failing if the file already exists\n",
    "* `'a'` - open for writing, appending to the end of the file if it exists\n",
    "* `'b'` - binary mode\n",
    "* `'t'` - text mode (default)\n",
    "* `'+'` - open a disk file for updating (reading and writing)\n",
    "\n",
    "To make this tutorial more interesting, let's create a purpose for our code. Our goal is to create a logging system for players and their rolls. Every time a player rolls, we will add it to our log. We will also add a timestamp to each roll. We will store the log in a file called `log.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "# First, we'll open a file\n",
    "fp = open(\"log.txt\", \"w\")\n",
    "\n",
    "# Let's create a list of players\n",
    "players = [\"Naomi\", \"James\", \"Amos\", \"Bobbie\"]\n",
    "\n",
    "# Let's roll a d20 for each player and write it in the log, including a timestamp\n",
    "for player in players:\n",
    "    roll = random.randint(1, 20)\n",
    "    timestamp = datetime.datetime.now()\n",
    "    fp.write(f\"{timestamp} - {player} rolled a {roll}\\n\")\n",
    "\n",
    "# Finally, let's close the file\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't recommended to open and close the file manually like this. Instead, we will use the `with` statement. This will ensure that the file is closed properly even if an exception is raised.\n",
    "\n",
    "Additionally, it is possible that calling `write` without using `with` will not write to the file immediately. Instead, it will be buffered and written later. Using `with` will ensure that the file is written to immediately.\n",
    "\n",
    "```python\n",
    "import datetime\n",
    "\n",
    "with open('log.txt', 'a') as f:\n",
    "    f.write(f'{datetime.datetime.now()}: {player} rolled {roll}\\n')\n",
    "```\n",
    "\n",
    "## Reading and writing binary files\n",
    "\n",
    "For the next example, we will write the user's rolls as binary. Each user will get their own file so that we can easily read their rolls later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naomi [2, 13, 18, 8, 16]\n",
      "James [7, 10, 17, 15, 15]\n",
      "Amos [19, 9, 11, 6, 3]\n",
      "Bobbie [16, 5, 18, 13, 1]\n"
     ]
    }
   ],
   "source": [
    "for player in players:\n",
    "    rolls = [random.randint(1, 20) for _ in range(5)]\n",
    "    with open(\"rolls/\" + player + \".bin\", \"wb\") as fp:\n",
    "        fp.write(bytes(rolls))\n",
    "\n",
    "# To verify, let's open the files and print the contents\n",
    "for player in players:\n",
    "    with open(\"rolls/\" + player + \".bin\", \"rb\") as fp:\n",
    "        print(player, list(fp.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from CSV files\n",
    "\n",
    "Python has a built-in module for reading and writing CSV files. CSV stands for comma-separated values. It is a common format for storing tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1727', 'composer': 'Schubert', 'composition': 'Piano Quintet in A major', 'movement': '2. Andante', 'ensemble': 'Piano Quintet', 'source': 'European Archive', 'transcriber': 'http://tirolmusic.blogspot.com/', 'catalog_name': 'OP114', 'seconds': '447'}\n",
      "{'id': '1728', 'composer': 'Schubert', 'composition': 'Piano Quintet in A major', 'movement': '3. Scherzo: Presto', 'ensemble': 'Piano Quintet', 'source': 'European Archive', 'transcriber': 'http://tirolmusic.blogspot.com/', 'catalog_name': 'OP114', 'seconds': '251'}\n",
      "{'id': '1729', 'composer': 'Schubert', 'composition': 'Piano Quintet in A major', 'movement': '4. Andantino - Allegretto', 'ensemble': 'Piano Quintet', 'source': 'European Archive', 'transcriber': 'http://tirolmusic.blogspot.com/', 'catalog_name': 'OP114', 'seconds': '444'}\n",
      "{'id': '1730', 'composer': 'Schubert', 'composition': 'Piano Quintet in A major', 'movement': '5. Allegro giusto', 'ensemble': 'Piano Quintet', 'source': 'European Archive', 'transcriber': 'http://tirolmusic.blogspot.com/', 'catalog_name': 'OP114', 'seconds': '368'}\n",
      "{'id': '1733', 'composer': 'Schubert', 'composition': 'Piano Sonata in A major', 'movement': '2. Andantino', 'ensemble': 'Solo Piano', 'source': 'Museopen', 'transcriber': 'Segundo G. Yogore', 'catalog_name': 'D959', 'seconds': '546'}\n",
      "There are 35 Violin pieces in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Load and parse CSV\n",
    "import csv\n",
    "\n",
    "# Store the data in a list of dictionaries\n",
    "data = []\n",
    "with open(\"../data/musicnet_metadata.csv\", \"r\") as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    keys = next(reader)\n",
    "    for row in reader:\n",
    "        data.append(dict(zip(keys, row)))\n",
    "\n",
    "# Let's print the first 5 rows\n",
    "for row in data[:5]:\n",
    "    print(row)\n",
    "\n",
    "# Count the number of Violin pieces are in the dataset\n",
    "count = 0\n",
    "for row in data:\n",
    "    if \"Violin\" in row[\"ensemble\"]:\n",
    "        count += 1\n",
    "\n",
    "print(f\"There are {count} Violin pieces in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: List all works in the dataset by Bach for Solo Violin\n",
    "\n",
    "Now that we have our data loaded. Let's use list comprehensions to print out all the works by Bach for solo violin. Our formatted table should show the following columns:\n",
    "- id\n",
    "- composition name\n",
    "- seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 Bach pieces in the dataset\n",
      "{'id': '2186', 'composer': 'Bach', 'composition': 'Violin Partita No 3 in E major', 'movement': '1. Preludio', 'ensemble': 'Solo Violin', 'source': 'Oliver Colbentston', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1006', 'seconds': '214'}\n",
      "{'id': '2191', 'composer': 'Bach', 'composition': 'Violin Partita No 3 in E major', 'movement': '6. Bourree', 'ensemble': 'Solo Violin', 'source': 'Oliver Colbentston', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1006', 'seconds': '102'}\n",
      "{'id': '2241', 'composer': 'Bach', 'composition': 'Violin Sonata No 1 in G minor', 'movement': '1. Adagio', 'ensemble': 'Solo Violin', 'source': 'European Archive', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1001', 'seconds': '242'}\n",
      "{'id': '2242', 'composer': 'Bach', 'composition': 'Violin Sonata No 1 in G minor', 'movement': '2. Fuga', 'ensemble': 'Solo Violin', 'source': 'European Archive', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1001', 'seconds': '312'}\n",
      "{'id': '2243', 'composer': 'Bach', 'composition': 'Violin Sonata No 1 in G minor', 'movement': '3. Siciliana', 'ensemble': 'Solo Violin', 'source': 'European Archive', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1001', 'seconds': '193'}\n",
      "{'id': '2244', 'composer': 'Bach', 'composition': 'Violin Sonata No 1 in G minor', 'movement': '4. Presto', 'ensemble': 'Solo Violin', 'source': 'European Archive', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1001', 'seconds': '214'}\n",
      "{'id': '2288', 'composer': 'Bach', 'composition': 'Violin Partita No 1 in B minor', 'movement': '2. Corrente', 'ensemble': 'Solo Violin', 'source': 'John Garner', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1002', 'seconds': '191'}\n",
      "{'id': '2289', 'composer': 'Bach', 'composition': 'Violin Partita No 1 in B minor', 'movement': '3. Sarabande', 'ensemble': 'Solo Violin', 'source': 'John Garner', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1002', 'seconds': '203'}\n",
      "{'id': '2659', 'composer': 'Bach', 'composition': 'Violin Partita No 1 in B minor', 'movement': '6. Double', 'ensemble': 'Solo Violin', 'source': 'John Garner', 'transcriber': 'suzumidi', 'catalog_name': 'BWV1002', 'seconds': '108'}\n"
     ]
    }
   ],
   "source": [
    "# Filter all lines that are written by Bach\n",
    "bach = [row for row in data if \"Bach\" in row[\"composer\"] and \"Solo Violin\" in row[\"ensemble\"]]\n",
    "\n",
    "# Print the number of Bach pieces\n",
    "print(f\"There are {len(bach)} Bach pieces in the dataset\")\n",
    "\n",
    "# Print them all out\n",
    "for row in bach:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this dataset is missing quite a few pieces. Bach wrote 6 sonatas and partitas for solo violin. We only have 3 of them in this dataset. Of the 3 that are included, partitas 1 and 3 are incomplete as well.\n",
    "\n",
    "Based on the order of the ids, it looks like this data should be present. Let's see if we can fill some of this in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The times are based on Hilary Hahn's recordings\n",
    "\n",
    "missing_pieces = [\n",
    "    {\n",
    "        \"id\": \"2679\",\n",
    "        \"composer\": \"Bach\",\n",
    "        \"composition\": \"Violin Partita No 3 in E major\",\n",
    "        \"movement\": \"2. Loure\",\n",
    "        \"ensemble\": \"Solo Violin\",\n",
    "        \"source\": \"DASC 5300 Fall 2023\",\n",
    "        \"transcriber\": \"none\",\n",
    "        \"catalog_name\": \"BWV 1006\",\n",
    "        \"seconds\": \"287\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2680\",\n",
    "        \"composer\": \"Bach\",\n",
    "        \"composition\": \"Violin Partita No 3 in E major\",\n",
    "        \"movement\": \"3. Gavotte en Rondeau\",\n",
    "        \"ensemble\": \"Solo Violin\",\n",
    "        \"source\": \"DASC 5300 Fall 2023\",\n",
    "        \"transcriber\": \"none\",\n",
    "        \"catalog_name\": \"BWV 1006\",\n",
    "        \"seconds\": \"196\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2681\",\n",
    "        \"composer\": \"Bach\",\n",
    "        \"composition\": \"Violin Partita No 3 in E major\",\n",
    "        \"movement\": \"4. Menuet I\",\n",
    "        \"ensemble\": \"Solo Violin\",\n",
    "        \"source\": \"DASC 5300 Fall 2023\",\n",
    "        \"transcriber\": \"none\",\n",
    "        \"catalog_name\": \"BWV 1006\",\n",
    "        \"seconds\": \"113\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2682\",\n",
    "        \"composer\": \"Bach\",\n",
    "        \"composition\": \"Violin Partita No 3 in E major\",\n",
    "        \"movement\": \"5. Menuet II\",\n",
    "        \"ensemble\": \"Solo Violin\",\n",
    "        \"source\": \"DASC 5300 Fall 2023\",\n",
    "        \"transcriber\": \"none\",\n",
    "        \"catalog_name\": \"BWV 1006\",\n",
    "        \"seconds\": \"183\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Our Output\n",
    "\n",
    "Viewing raw lines of a dictionary or CSV file is less than ideal. Let's format our output to make it easier to read. We will format the filtered Bach data. Since we know that every piece was written by him, we don't need to show that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 Bach pieces in the dataset\n",
      "Composition                    | Movement              | ID  \n",
      "-------------------------------------------------------------\n",
      "Violin Partita No 1 in B minor | 2. Corrente           | 2288\n",
      "Violin Partita No 1 in B minor | 3. Sarabande          | 2289\n",
      "Violin Partita No 1 in B minor | 6. Double             | 2659\n",
      "Violin Partita No 3 in E major | 1. Preludio           | 2186\n",
      "Violin Partita No 3 in E major | 2. Loure              | 2679\n",
      "Violin Partita No 3 in E major | 3. Gavotte en Rondeau | 2680\n",
      "Violin Partita No 3 in E major | 4. Menuet I           | 2681\n",
      "Violin Partita No 3 in E major | 5. Menuet II          | 2682\n",
      "Violin Partita No 3 in E major | 6. Bourree            | 2191\n",
      "Violin Sonata No 1 in G minor  | 1. Adagio             | 2241\n",
      "Violin Sonata No 1 in G minor  | 2. Fuga               | 2242\n",
      "Violin Sonata No 1 in G minor  | 3. Siciliana          | 2243\n",
      "Violin Sonata No 1 in G minor  | 4. Presto             | 2244\n"
     ]
    }
   ],
   "source": [
    "# Let's add the missing pieces to our dataset\n",
    "data.extend(missing_pieces)\n",
    "\n",
    "# Refilter the Bach pieces\n",
    "bach = [row for row in data if \"Bach\" in row[\"composer\"] and \"Solo Violin\" in row[\"ensemble\"]]\n",
    "print(f\"There are {len(bach)} Bach pieces in the dataset\")\n",
    "\n",
    "# Print them all out, sorted by composition then movement\n",
    "composition_width = max(len(row[\"composition\"]) for row in bach)\n",
    "movement_width = max(len(row[\"movement\"]) for row in bach)\n",
    "id_width = max(len(row[\"id\"]) for row in bach)\n",
    "\n",
    "print(\"{:<{}} | {:<{}} | {:<{}}\".format(\"Composition\", composition_width, \"Movement\", movement_width, \"ID\", id_width))\n",
    "print(\"-\" * (composition_width + movement_width + id_width + 6))\n",
    "for row in sorted(bach, key=lambda x: (x[\"composition\"], x[\"movement\"])):\n",
    "    print(\"{:<{}} | {:<{}} | {:<{}}\".format(row[\"composition\"], composition_width, row[\"movement\"], movement_width, row[\"id\"], id_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that it looks good, let's write the updated dataset to a new file\n",
    "with open(\"../data/musicnet_metadata_updated.csv\", \"w\") as fp:\n",
    "    writer = csv.DictWriter(fp, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing JSON\n",
    "\n",
    "JSON stands for JavaScript Object Notation. It is a common format for storing and transmitting data. It is often used for web APIs. Python has a built-in module for reading and writing JSON files.\n",
    "\n",
    "Let's open the CSV file from the previous example and write it to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse CSV\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Store the data in a list of dictionaries\n",
    "data = []\n",
    "with open(\"../data/musicnet_metadata.csv\", \"r\") as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    keys = next(reader)\n",
    "    for row in reader:\n",
    "        data.append(dict(zip(keys, row)))\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(\"musicnet_metadata.json\", \"w\") as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing `pickle` Files\n",
    "\n",
    "Python has a built-in module for reading and writing `pickle` files. `pickle` is a binary format for serializing Python objects. It is not human-readable, but it is very useful for storing and transmitting data. Note that `pickle` is not secure. It is possible to create malicious `pickle` files that can execute arbitrary code when loaded. Also, other languages cannot natively read `pickle` files. However, there are usually libraries available for reading `pickle` files in other languages.\n",
    "\n",
    "Let's start by writing the list from the previous example to a `pickle` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52353\n"
     ]
    }
   ],
   "source": [
    "# Write the data to a pickle file\n",
    "import pickle\n",
    "\n",
    "with open(\"musicnet_metadata.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(data, fp)\n",
    "\n",
    "# Get the file size of the pickle file we just wrote\n",
    "import os\n",
    "\n",
    "print(os.path.getsize(\"musicnet_metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing Class Objects\n",
    "\n",
    "Serializing objects is simple with Python. Let's create a simple class to represent the attributes of our dataset. We can then convert our previous list of dictionary data to a list of objects. Finally, we can serialize the list of objects to a `pickle` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54352\n"
     ]
    }
   ],
   "source": [
    "# Create a class for our data\n",
    "class Piece:\n",
    "    def __init__(self, data):\n",
    "        self.id = data[\"id\"]\n",
    "        self.composer = data[\"composer\"]\n",
    "        self.composition = data[\"composition\"]\n",
    "        self.movement = data[\"movement\"]\n",
    "        self.ensemble = data[\"ensemble\"]\n",
    "        self.source = data[\"source\"]\n",
    "        self.transcriber = data[\"transcriber\"]\n",
    "        self.catalog_name = data[\"catalog_name\"]\n",
    "        self.seconds = data[\"seconds\"]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Piece {self.id}: {self.composer} - {self.composition}>\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.composer} - {self.composition}\"\n",
    "\n",
    "# Convert our data into a list of objects and write it to a pickle file\n",
    "pieces = [Piece(d) for d in data]\n",
    "with open(\"musicnet_metadata.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(pieces, fp)\n",
    "\n",
    "# Print the size of this new file\n",
    "print(os.path.getsize(\"musicnet_metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Write the class objects to JSON\n",
    "\n",
    "We can't write the class objects to JSON directly. We need to convert them to a dictionary first. We can do this by implementing the `__dict__` method. Without explicitly defining `__dict__`, it will return the default dictionary for the class. However, we can override it to return a custom dictionary. The default version will include all of the class attributes. We can use this to our advantage to convert the class to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Save the class data as JSON\n",
    "import json\n",
    "\n",
    "# Write the list of class objects to a JSON file\n",
    "with open(\"musicnet_metadata.json\", \"w\") as fp:\n",
    "    json.dump(pieces, fp, default=lambda o: o.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
